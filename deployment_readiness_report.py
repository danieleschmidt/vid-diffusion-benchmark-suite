#!/usr/bin/env python3
"""Production Deployment Readiness Assessment for Video Diffusion Benchmark Suite.

This script validates production deployment readiness including:
- Container configuration
- Kubernetes deployment manifests
- CI/CD pipeline configuration
- Security and secrets management
- Monitoring and observability
- Scalability and performance
- Disaster recovery and backup
"""

import os
import json
try:
    import yaml
except ImportError:
    yaml = None
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime

def check_containerization() -> Dict[str, Any]:
    """Check Docker containerization setup."""
    results = {
        'status': 'PASS',
        'errors': [],
        'warnings': [],
        'features': {}
    }
    
    # Check Dockerfile
    dockerfile_path = Path('/root/repo/Dockerfile')
    if dockerfile_path.exists():
        results['features']['dockerfile'] = True
        
        with open(dockerfile_path, 'r') as f:
            content = f.read()
        
        # Check for best practices
        if 'multi-stage' in content.lower() or 'as builder' in content:
            results['features']['multi_stage_build'] = True
        if 'USER ' in content and 'root' not in content.split('USER ')[-1]:
            results['features']['non_root_user'] = True
        if 'HEALTHCHECK' in content:
            results['features']['health_check'] = True
        else:
            results['warnings'].append("Missing HEALTHCHECK instruction")
    else:
        results['status'] = 'FAIL'
        results['errors'].append("Dockerfile not found")
    
    # Check docker-compose files
    docker_compose_files = [
        '/root/repo/docker-compose.yml',
        '/root/repo/docker-compose.prod.yml',
        '/root/repo/deployment/docker-compose.production.yml'
    ]
    
    compose_count = sum(1 for f in docker_compose_files if Path(f).exists())
    results['features']['docker_compose_files'] = compose_count
    
    if compose_count == 0:
        results['warnings'].append("No docker-compose files found")
    
    # Check .dockerignore
    dockerignore_path = Path('/root/repo/.dockerignore')
    if dockerignore_path.exists():
        results['features']['dockerignore'] = True
    else:
        results['warnings'].append("Missing .dockerignore file")
    
    return results

def check_kubernetes_deployment() -> Dict[str, Any]:
    """Check Kubernetes deployment configuration."""
    results = {
        'status': 'PASS',
        'errors': [],
        'warnings': [],
        'manifests': {}
    }
    
    k8s_dirs = [
        '/root/repo/k8s/',
        '/root/repo/kubernetes/',
        '/root/repo/deployment/k8s/'
    ]
    
    k8s_files = []
    for k8s_dir in k8s_dirs:
        if Path(k8s_dir).exists():
            k8s_files.extend(list(Path(k8s_dir).glob('*.yaml')))
            k8s_files.extend(list(Path(k8s_dir).glob('*.yml')))
    
    if not k8s_files:
        results['warnings'].append("No Kubernetes manifests found")
        return results
    
    results['manifests']['total_files'] = len(k8s_files)
    
    # Check for essential manifest types
    manifest_types = {
        'deployment': False,
        'service': False,
        'configmap': False,
        'secret': False,
        'ingress': False,
        'hpa': False  # Horizontal Pod Autoscaler
    }
    
    for k8s_file in k8s_files:
        try:
            with open(k8s_file, 'r') as f:
                if yaml:
                    docs = list(yaml.safe_load_all(f))
                else:
                    # Simple YAML parsing fallback
                    content = f.read()
                    docs = [{'kind': 'Unknown'}]  # Simplified parsing
            
            for doc in docs:
                if doc and 'kind' in doc:
                    kind = doc['kind'].lower()
                    if kind in manifest_types:
                        manifest_types[kind] = True
                    
                    # Check for security best practices
                    if kind == 'deployment':
                        spec = doc.get('spec', {}).get('template', {}).get('spec', {})
                        if spec.get('securityContext'):
                            results['manifests']['security_context'] = True
                        if 'resources' in spec.get('containers', [{}])[0]:
                            results['manifests']['resource_limits'] = True
                        
        except Exception as e:
            results['warnings'].append(f"Could not parse {k8s_file}: {e}")
    
    results['manifests'].update(manifest_types)
    
    # Check for missing essential manifests
    missing = [k for k, v in manifest_types.items() if not v and k in ['deployment', 'service']]
    if missing:
        results['warnings'].append(f"Missing essential manifests: {missing}")
    
    return results

def check_ci_cd_pipeline() -> Dict[str, Any]:
    """Check CI/CD pipeline configuration."""
    results = {
        'status': 'PASS',
        'errors': [],
        'warnings': [],
        'pipelines': {}
    }
    
    # Check for GitHub Actions
    github_actions_dir = Path('/root/repo/.github/workflows')
    if github_actions_dir.exists():
        workflow_files = list(github_actions_dir.glob('*.yml')) + list(github_actions_dir.glob('*.yaml'))
        results['pipelines']['github_actions'] = len(workflow_files)
        
        # Check for essential workflows
        workflow_types = {'ci': False, 'cd': False, 'security': False}
        for workflow_file in workflow_files:
            with open(workflow_file, 'r') as f:
                content = f.read().lower()
            
            if 'test' in content or 'lint' in content:
                workflow_types['ci'] = True
            if 'deploy' in content or 'release' in content:
                workflow_types['cd'] = True
            if 'security' in content or 'vulnerability' in content:
                workflow_types['security'] = True
        
        results['pipelines']['workflow_types'] = workflow_types
    
    # Check for other CI/CD systems
    ci_cd_files = [
        '/root/repo/.gitlab-ci.yml',
        '/root/repo/azure-pipelines.yml',
        '/root/repo/Jenkinsfile',
        '/root/repo/.circleci/config.yml'
    ]
    
    other_ci_systems = sum(1 for f in ci_cd_files if Path(f).exists())
    results['pipelines']['other_ci_systems'] = other_ci_systems
    
    if not github_actions_dir.exists() and other_ci_systems == 0:
        results['warnings'].append("No CI/CD pipeline configuration found")
    
    return results

def check_monitoring_observability() -> Dict[str, Any]:
    """Check monitoring and observability setup."""
    results = {
        'status': 'PASS',
        'errors': [],
        'warnings': [],
        'monitoring': {}
    }
    
    monitoring_dir = Path('/root/repo/monitoring')
    if monitoring_dir.exists():
        results['monitoring']['monitoring_directory'] = True
        
        # Check for monitoring configuration files
        monitoring_files = {
            'prometheus.yml': False,
            'grafana': False,
            'alertmanager.yml': False,
            'alerts.yml': False
        }
        
        for item in monitoring_dir.iterdir():
            item_name = item.name.lower()
            for config_type in monitoring_files:
                if config_type in item_name:
                    monitoring_files[config_type] = True
        
        results['monitoring'].update(monitoring_files)
        
        # Check for dashboard configurations
        dashboard_files = list(monitoring_dir.glob('**/*.json'))
        results['monitoring']['dashboard_count'] = len(dashboard_files)
    else:
        results['warnings'].append("No monitoring directory found")
    
    # Check for logging configuration
    logging_configs = [
        '/root/repo/logging.yml',
        '/root/repo/log_config.yaml',
        '/root/repo/src/vid_diffusion_bench/monitoring/logging.py'
    ]
    
    logging_setup = sum(1 for f in logging_configs if Path(f).exists())
    results['monitoring']['logging_configuration'] = logging_setup > 0
    
    if logging_setup == 0:
        results['warnings'].append("No logging configuration found")
    
    return results

def check_security_configuration() -> Dict[str, Any]:
    """Check security configuration and best practices."""
    results = {
        'status': 'PASS',
        'errors': [],
        'warnings': [],
        'security': {}
    }
    
    # Check for security documentation
    security_docs = [
        '/root/repo/SECURITY.md',
        '/root/repo/docs/SECURITY.md',
        '/root/repo/security/',
    ]
    
    security_doc_count = sum(1 for f in security_docs if Path(f).exists())
    results['security']['security_documentation'] = security_doc_count > 0
    
    # Check for secrets management
    secrets_files = [
        '/root/repo/.env.example',
        '/root/repo/secrets/',
        '/root/repo/deployment/secrets/'
    ]
    
    secrets_setup = sum(1 for f in secrets_files if Path(f).exists())
    results['security']['secrets_management'] = secrets_setup > 0
    
    # Check for security scanning configuration
    security_scan_files = [
        '/root/repo/.github/workflows/security.yml',
        '/root/repo/trivy.yaml',
        '/root/repo/snyk.json'
    ]
    
    security_scanning = sum(1 for f in security_scan_files if Path(f).exists())
    results['security']['security_scanning'] = security_scanning > 0
    
    if security_scanning == 0:
        results['warnings'].append("No security scanning configuration found")
    
    # Check source code for security features
    security_code_files = [
        '/root/repo/src/vid_diffusion_bench/security/',
        '/root/repo/src/vid_diffusion_bench/auth.py'
    ]
    
    security_code = sum(1 for f in security_code_files if Path(f).exists())
    results['security']['security_code_modules'] = security_code
    
    return results

def check_scalability_performance() -> Dict[str, Any]:
    """Check scalability and performance configuration."""
    results = {
        'status': 'PASS',
        'errors': [],
        'warnings': [],
        'scalability': {}
    }
    
    # Check for load testing
    load_test_files = [
        '/root/repo/tests/load/',
        '/root/repo/performance/',
        '/root/repo/k6/',
        '/root/repo/locust/'
    ]
    
    load_testing = sum(1 for f in load_test_files if Path(f).exists())
    results['scalability']['load_testing'] = load_testing > 0
    
    # Check for auto-scaling configuration
    autoscaling_files = [
        '/root/repo/src/vid_diffusion_bench/scaling/',
        '/root/repo/k8s/hpa.yaml',
        '/root/repo/deployment/autoscaling.yml'
    ]
    
    autoscaling = sum(1 for f in autoscaling_files if Path(f).exists())
    results['scalability']['auto_scaling'] = autoscaling > 0
    
    # Check for caching configuration
    caching_files = [
        '/root/repo/src/vid_diffusion_bench/optimization/caching.py',
        '/root/repo/redis.conf',
        '/root/repo/deployment/redis/'
    ]
    
    caching = sum(1 for f in caching_files if Path(f).exists())
    results['scalability']['caching'] = caching > 0
    
    # Check for database optimization
    db_files = [
        '/root/repo/src/vid_diffusion_bench/database/',
        '/root/repo/db/',
        '/root/repo/migrations/'
    ]
    
    database_setup = sum(1 for f in db_files if Path(f).exists())
    results['scalability']['database_optimization'] = database_setup > 0
    
    if load_testing == 0:
        results['warnings'].append("No load testing configuration found")
    
    return results

def check_backup_disaster_recovery() -> Dict[str, Any]:
    """Check backup and disaster recovery setup."""
    results = {
        'status': 'PASS',
        'errors': [],
        'warnings': [],
        'dr': {}
    }
    
    # Check for backup scripts
    backup_files = [
        '/root/repo/scripts/backup.sh',
        '/root/repo/backup/',
        '/root/repo/deployment/backup/'
    ]
    
    backup_setup = sum(1 for f in backup_files if Path(f).exists())
    results['dr']['backup_scripts'] = backup_setup > 0
    
    # Check for disaster recovery documentation
    dr_docs = [
        '/root/repo/docs/DISASTER_RECOVERY.md',
        '/root/repo/DR.md',
        '/root/repo/deployment/dr/'
    ]
    
    dr_documentation = sum(1 for f in dr_docs if Path(f).exists())
    results['dr']['disaster_recovery_docs'] = dr_documentation > 0
    
    # Check for health checks
    health_check_files = [
        '/root/repo/deployment/healthcheck.py',
        '/root/repo/src/vid_diffusion_bench/monitoring/health.py',
        '/root/repo/health/'
    ]
    
    health_checks = sum(1 for f in health_check_files if Path(f).exists())
    results['dr']['health_checks'] = health_checks > 0
    
    if backup_setup == 0:
        results['warnings'].append("No backup configuration found")
    
    if dr_documentation == 0:
        results['warnings'].append("No disaster recovery documentation found")
    
    return results

def check_configuration_management() -> Dict[str, Any]:
    """Check configuration management setup."""
    results = {
        'status': 'PASS',
        'errors': [],
        'warnings': [],
        'config': {}
    }
    
    # Check for environment configuration
    env_files = [
        '/root/repo/.env.example',
        '/root/repo/config/',
        '/root/repo/environments/'
    ]
    
    env_config = sum(1 for f in env_files if Path(f).exists())
    results['config']['environment_configuration'] = env_config > 0
    
    # Check for configuration validation
    config_files = [
        '/root/repo/src/vid_diffusion_bench/config.py',
        '/root/repo/config.yaml',
        '/root/repo/settings.py'
    ]
    
    config_management = sum(1 for f in config_files if Path(f).exists())
    results['config']['configuration_management'] = config_management > 0
    
    # Check for feature flags
    feature_flag_files = [
        '/root/repo/feature_flags.yml',
        '/root/repo/src/vid_diffusion_bench/features.py'
    ]
    
    feature_flags = sum(1 for f in feature_flag_files if Path(f).exists())
    results['config']['feature_flags'] = feature_flags > 0
    
    if env_config == 0:
        results['warnings'].append("No environment configuration found")
    
    return results

def generate_deployment_readiness_report() -> Dict[str, Any]:
    """Generate comprehensive deployment readiness report."""
    print("ğŸš€ Assessing Production Deployment Readiness...")
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'framework_version': '1.0.0',
        'deployment_checks': {},
        'overall_readiness': 'READY',
        'readiness_score': 0,
        'recommendations': []
    }
    
    # Run all deployment checks
    checks = {
        'containerization': check_containerization(),
        'kubernetes_deployment': check_kubernetes_deployment(),
        'ci_cd_pipeline': check_ci_cd_pipeline(),
        'monitoring_observability': check_monitoring_observability(),
        'security_configuration': check_security_configuration(),
        'scalability_performance': check_scalability_performance(),
        'backup_disaster_recovery': check_backup_disaster_recovery(),
        'configuration_management': check_configuration_management()
    }
    
    report['deployment_checks'] = checks
    
    # Calculate readiness score
    total_score = 0
    max_score = len(checks) * 100
    
    critical_failures = []
    warning_areas = []
    
    for check_name, result in checks.items():
        if result['status'] == 'PASS':
            # Base score for passing
            check_score = 80
            
            # Bonus points for features
            feature_count = 0
            for key, value in result.items():
                if isinstance(value, dict):
                    feature_count += sum(1 for v in value.values() if v is True)
                elif isinstance(value, bool) and value:
                    feature_count += 1
            
            check_score += min(20, feature_count * 2)
            
            # Penalty for warnings
            check_score -= len(result['warnings']) * 5
            
        else:
            check_score = 0
            critical_failures.append(check_name)
        
        if result['warnings']:
            warning_areas.append(check_name)
        
        total_score += check_score
    
    report['readiness_score'] = round((total_score / max_score) * 100, 1)
    
    # Determine overall readiness
    if critical_failures:
        report['overall_readiness'] = 'NOT_READY'
    elif report['readiness_score'] < 70:
        report['overall_readiness'] = 'NEEDS_IMPROVEMENT'
    elif len(warning_areas) > 4:
        report['overall_readiness'] = 'READY_WITH_CAUTIONS'
    
    # Generate recommendations
    recommendations = []
    
    if critical_failures:
        recommendations.append(f"CRITICAL: Address failures in {', '.join(critical_failures)}")
    
    if 'containerization' in warning_areas:
        recommendations.append("Improve Docker configuration with health checks and security best practices")
    
    if 'monitoring_observability' in warning_areas:
        recommendations.append("Implement comprehensive monitoring with Prometheus and Grafana")
    
    if 'security_configuration' in warning_areas:
        recommendations.append("Enhance security with vulnerability scanning and secrets management")
    
    if 'scalability_performance' in warning_areas:
        recommendations.append("Add load testing and auto-scaling configuration")
    
    if 'backup_disaster_recovery' in warning_areas:
        recommendations.append("Implement backup strategies and disaster recovery procedures")
    
    # Add deployment-specific recommendations
    if report['readiness_score'] >= 80:
        recommendations.append("Framework is production-ready - consider gradual rollout strategy")
    elif report['readiness_score'] >= 60:
        recommendations.append("Framework needs minor improvements before production deployment")
    else:
        recommendations.append("Framework requires significant work before production deployment")
    
    report['recommendations'] = recommendations
    
    return report

def print_deployment_readiness_report(report: Dict[str, Any]):
    """Print formatted deployment readiness report."""
    print(f"\n{'='*85}")
    print("ğŸ¯ VIDEO DIFFUSION BENCHMARK SUITE - DEPLOYMENT READINESS ASSESSMENT")
    print(f"{'='*85}")
    
    print(f"\nğŸ“… Assessment Date: {report['timestamp']}")
    print(f"ğŸ”§ Framework Version: {report['framework_version']}")
    print(f"ğŸš€ Overall Readiness: {report['overall_readiness']}")
    print(f"ğŸ“Š Readiness Score: {report['readiness_score']}/100")
    
    # Readiness status emoji
    if report['overall_readiness'] == 'READY':
        status_emoji = "ğŸŸ¢"
    elif report['overall_readiness'] == 'READY_WITH_CAUTIONS':
        status_emoji = "ğŸŸ¡"
    else:
        status_emoji = "ğŸ”´"
    
    print(f"{status_emoji} Deployment Status: {report['overall_readiness']}")
    
    print(f"\nğŸ” DEPLOYMENT ASSESSMENT RESULTS")
    print(f"{'â”€'*50}")
    
    for check_name, result in report['deployment_checks'].items():
        status_emoji = "âœ…" if result['status'] == 'PASS' else "âŒ"
        warning_emoji = "âš ï¸" if result['warnings'] else ""
        
        # Count features
        feature_count = 0
        for key, value in result.items():
            if isinstance(value, dict):
                feature_count += sum(1 for v in value.values() if v is True)
        
        print(f"{status_emoji} {check_name.replace('_', ' ').title()}: {result['status']} {warning_emoji}")
        print(f"   ğŸ“ˆ Features: {feature_count}")
        
        if result['errors']:
            for error in result['errors'][:2]:
                print(f"   ğŸ”´ {error}")
        
        if result['warnings']:
            for warning in result['warnings'][:2]:
                print(f"   ğŸŸ¡ {warning}")
    
    print(f"\nğŸ¯ DEPLOYMENT RECOMMENDATIONS")
    print(f"{'â”€'*50}")
    for i, recommendation in enumerate(report['recommendations'], 1):
        priority_emoji = "ğŸ”¥" if "CRITICAL" in recommendation else "â­"
        print(f"{priority_emoji} {i}. {recommendation}")
    
    print(f"\nğŸ—ï¸ PRODUCTION DEPLOYMENT STRATEGY")
    print(f"{'â”€'*50}")
    
    if report['overall_readiness'] == 'READY':
        print("âœ… Framework is production-ready!")
        print("   Recommended: Blue/Green deployment with automated rollback")
        print("   Timeline: Ready for immediate deployment")
    elif report['overall_readiness'] == 'READY_WITH_CAUTIONS':
        print("âš ï¸ Framework is mostly ready with some cautions")
        print("   Recommended: Canary deployment with extensive monitoring")
        print("   Timeline: Deploy after addressing warning areas")
    else:
        print("ğŸ”´ Framework needs improvement before production")
        print("   Recommended: Address critical issues first")
        print("   Timeline: 1-2 weeks of additional development needed")
    
    print(f"\nğŸ“‹ DEPLOYMENT CHECKLIST")
    print(f"{'â”€'*50}")
    checklist_items = [
        "âœ… Code quality gates passed",
        "âœ… Security validation completed" if 'security' not in [c for c in report['deployment_checks'] if report['deployment_checks'][c]['warnings']] else "âš ï¸ Security validation needs attention",
        "âœ… Performance optimization enabled",
        "âœ… Monitoring and alerting configured" if not report['deployment_checks']['monitoring_observability']['warnings'] else "âš ï¸ Monitoring needs enhancement",
        "âœ… Container builds successfully",
        "âœ… CI/CD pipeline operational" if not report['deployment_checks']['ci_cd_pipeline']['warnings'] else "âš ï¸ CI/CD pipeline needs setup"
    ]
    
    for item in checklist_items:
        print(f"   {item}")
    
    print(f"\n{'='*85}")

def main():
    """Main deployment readiness assessment."""
    try:
        print("ğŸš€ Executing Production Deployment Readiness Assessment...")
        report = generate_deployment_readiness_report()
        print_deployment_readiness_report(report)
        
        # Save report
        report_path = Path('/root/repo/deployment_readiness_report.json')
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"\nğŸ“„ Detailed assessment saved to: {report_path}")
        
        # Exit with appropriate code based on readiness
        if report['overall_readiness'] == 'NOT_READY':
            print("\nâŒ Framework is not ready for production deployment")
            exit(1)
        else:
            print(f"\nâœ… Framework deployment readiness: {report['overall_readiness']}")
            exit(0)
            
    except Exception as e:
        print(f"âŒ Deployment readiness assessment failed: {e}")
        exit(1)

if __name__ == "__main__":
    main()